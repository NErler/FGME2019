
<<packages part3, echo = FALSE>>=
library(knitr)
library(kableExtra)

library(splines)
library(mice)
library(miceadds)
library(lme4)
library(survival)

@

<<cache = TRUE, include = FALSE>>=
source(file.path(projdir, "Slides", "Rscripts/simdata_PartIII.R"))
@


\section{Settings where MICE may have problems}
\subsection{Quadratic effect}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Consider the case where the \blue{analysis model} (which we assume to be true)
is
$$y = \beta_0 + \beta_1 x + {\color{darkred}\bmath{\beta_2 x^2}} + \ldots,$$
i.e., $y$ has a \blue{quadratic relationship} with $x$, and $x$ is incomplete.

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
\centering\includegraphics[width = \linewidth]{figure/p_qdr1.pdf}
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The original data show a curved pattern.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to \blue{impute $x$} when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \ldots,$$
i.e., a \blue{linear relation} between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
\centering\includegraphics[width = \linewidth]{figure/p_qdr2.pdf}
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The imputed values \blue{distort the curved pattern} of the original data.
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

The model fitted on the imputed data gives \blue{severely biased results}; the
non-linear shape of the curve has almost completely disappeared.

\vspace*{1ex}
\vfill
\vspace*{1ex}

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
\centering\includegraphics[width = \linewidth]{figure/p_qdr3.pdf}
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<restab_qdr, echo = F, size = 'scriptsize'>>=
tabexqdr <- confint(lm0_qdr) %>%
  rbind(confint(lm_imp_qdr)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0_qdr$coef, lm_imp_qdr$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'x2'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  pack_rows("Original", 1, 3) %>%
  pack_rows("Imputed", 4, 6)

tabexqdr %>%
  gsub("x2", "$x^2$", .) %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}



\subsection{Interaction effect}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another example occurs when the analysis model (again, assumed to be true)
is
$$y = \beta_0 + \beta_x x + \beta_z z + {\color{darkred}\bmath{\beta_{xz} xz}} + \ldots,$$
i.e., $y$ has a \blue{non-linear relationship} with $x$ due to the
\blue{interaction term}.


\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
\centering\includegraphics[width = \linewidth]{figure/p_int1.pdf}
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The original data shows a ``$<$'' shaped pattern.
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to impute $x$ when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \theta_{12} z + \ldots,$$
i.e., a linear relation between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
\centering\includegraphics[width = \linewidth]{figure/p_int2.pdf}
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The ``$<$'' shaped pattern of the true data is \blue{distorted by the imputed values}.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
And the analysis on these naively imputed values leads to \blue{severely biased estimates}.

\vfill

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
\centering\includegraphics[width = \linewidth]{figure/p_int3.pdf}
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<echo = FALSE, size = 'scriptsize'>>=
restab_interact <- confint(lm0_int) %>%
  rbind(confint(lm_imp_int)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0_int$coef, lm_imp_int$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'z', 'x:z'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  pack_rows(index = c("Original" =  4, "Imputed" = 4))

restab_interact %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}



\subsection{Longitudinal outcome}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another setting where imputation with MICE is not straightforward is when
the \blue{outcome variable is longitudinal}.
\begin{columns}[onlytextwidth]
\begin{column}{0.54\linewidth}
\centering\includegraphics[width = \linewidth]{figure/plong1_1.pdf}
\end{column}
\begin{column}{0.45\linewidth}
<<ex_datatable, echo = FALSE, size = 'scriptsize', warning = F>>=
lsp <- rep("", nrow(ltDFexlong))
lsp[cumsum(table(subDFexlong$id[subDFexlong$id %in% ltDFexlong$id]))] <- "\\hdashline"

longdatatab <- ltDFexlong %>%
  plyr::mutate(time = cell_spec(time, 'latex', escape = FALSE,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000"))),
         id = cell_spec(id, 'latex', escape = FALSE,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  kable(format = 'latex', escape = FALSE, booktabs = T,
        linesep = lsp,
        align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = F)

longdatatab <- gsub("\\\\\n\\bottomrule", "", longdatatab, fixe = T)
longdatatab
@
\end{column}
\end{columns}
Here, $x_1, \ldots, x_4$ are baseline covariates, i.e., not measured repeatedly
(e.g. age at baseline, gender, education level, \ldots
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
If we use MICE in the data in this (long) format,
each row would be regarded as independent,
which may cause bias and \blue{inconsistent imputations}.

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.5\linewidth}
Imputed values of baseline covariates are imputed with different values,
creating data that could not have been observed.
\end{column}
\begin{column}{0.45\linewidth}
<<imptablong, echo = FALSE, size = 'scriptsize'>>=
imptablong <- rbind(impDFexlong[impDFexlong$id %in% subIDs, names(ltDFexlong)],
                    rep(NA, ncol(ltDFexlong)))
imptablong[sapply(imptablong, is.numeric)] <-
  round(imptablong[sapply(imptablong, is.numeric)], 2)

ltDFexlong2 <- ltDFexlong
ltDFexlong2[is.na(ltDFexlong2)] <- imptablong[is.na(ltDFexlong2)]

ltDFexlong2 <- ltDFexlong2 %>%
  plyr::mutate(time = cell_spec(time, 'latex', escape = FALSE,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  plyr::mutate(x2 = cell_spec(x2, "latex", escape = FALSE,
                        background = ifelse(is.na(ltDFexlong$x2),
                                       brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                       '#FFFFFF'))) %>%
  plyr::mutate(x3 = cell_spec(x3, "latex", escape = FALSE,
                        background = ifelse(is.na(ltDFexlong$x3),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  plyr::mutate(x4 = cell_spec(x4, "latex", escape = FALSE,
                        background = ifelse(is.na(ltDFexlong$x4),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  plyr::mutate(id = cell_spec(id, 'latex', escape = FALSE,
                        color = factor(id, c(IDs, "\\vdots"),
                                       c(brewer.pal(length(IDs),
                                                    name = "Dark2"),
                                         "#000000")))) %>%
  kable(format = 'latex', escape = FALSE, booktabs = T, linesep = lsp, align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = FALSE, digits = 2)

for (k in 1:8) {
  ltDFexlong2 <- gsub(paste0("\\cellcolor[HTML]{",
                             gsub("#", "", brewer.pal(8, "Dark2")[k])),
               paste0("\\cellcolor{Dark2", k, "!30"), ltDFexlong2, fixed = T)
}

gsub("\\\\\n\\bottomrule", "", ltDFexlong2, fixe = T)
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}[onlytextwidth]
\begin{column}{0.7\linewidth}
\centering\includegraphics[width = \linewidth]{figure/p_impcomplong.pdf}
\end{column}
\begin{column}{0.25\linewidth}
Estimates can be severely biased.
\end{column}
\end{columns}
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In some settings \blue{imputation in wide format} may be possible.

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.54\linewidth}
\only<handout>{
\centering\includegraphics[width = \linewidth]{figure/plong1_1b.pdf}
}
\only<beamer>{
\only<1>{
\centering\includegraphics[width = \linewidth]{figure/plong1_1.pdf}
}
\only<2>{
\centering\includegraphics[width = \linewidth]{figure/plong1_1b.pdf}
}}
\end{column}
\begin{column}{0.45\linewidth}
<<impwidedat, echo = FALSE, size = 'scriptsize', warning = F>>=
longdatatab
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

<<impwidedat2, size = 'scriptsize', echo = F>>=
subDFexlongwide[c("id",
            paste0("y.", c(1,3,5,7,9)),
            paste0("time.", c(1,3,5,7,9)))] %>%
  round(2) %>%
  rbind(., rep("\\vdots", 11)) %>%
  cbind(., '\\ldots' = c(rep("\\ldots", 4), "$\\ddots$")) %>%
  kable(format = 'latex', row.names = FALSE, booktabs = T, escape = F)
@

\bigskip

In this \blue{wide format data} frame, missing values in the outcome and measurement times
need to be imputed (to be able to use them as predictors to impute covariates),
even though we would not need to impute them for the analysis
(mixed model is valid when outcome measurements are M(C)AR).
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
\centering\includegraphics[width = \linewidth]{figure/p_compwide.pdf}
\end{column}
\begin{column}{0.3\linewidth}
Better, but large confidence intervals.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
\centering\includegraphics[width = \linewidth]{figure/plong2_1.pdf}
\end{column}
\begin{column}{0.3\linewidth}
When the data is very \blue{unbalanced}, transformation to wide format is not possible.

\bigskip

(Or at least transformation to wide format leads to variables with high proportions
of missing values.)
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile, label = naivelong]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.6\linewidth}
\centering\includegraphics[width = \linewidth]{figure/plong2_2.pdf}
\onslide<2->{
\centering\includegraphics[width = \linewidth]{figure/plong2_3.pdf}
}
\end{column}
\begin{column}{0.4\linewidth}
Naive approaches that are sometimes used are to
\begin{itemize}
\item \blue{ignore the outcome} in the imputation\onslide<2->{, or to}
\item<2-> use only the \blue{first/baseline outcome}
\end{itemize}

\bigskip

\onslide<3>{However, \blue{important information may be lost},
resulting in invalid imputations and biased results.}

\end{column}
\end{columns}
\end{frame}


\section{Requirements for MICE to work (well)}
\subsection{Joint and conditional distributions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The MICE algorithm is based on the idea of Gibbs sampling.

\bigskip
\pause

Gibbs sampling exploits the fact that a joint distribution is fully determined
by its full conditional distributions.

\begin{center}
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white} joint\\distribution}
}
\quad
\parbox[c]{3cm}{
\tikzfancyarrow[3cm]{\scriptsize \textbf{Gibbs}}\\
\onslide<2>{\tikzfancyarrow[3cm, shape border rotate = 180]{\scriptsize \textbf{MICE}}}
}
\quad
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white}full\\conditionals}
}
\end{center}

\onslide<2>{In MICE, the full conditionals are not derived from the joint distribution:\\
we directly specify the full conditionals and hope a joint distribution exists.}
\end{frame}


\subsection{Some conditions and definitions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Two important definitions:

\bigskip


\blue{Compatibility:}
\begin{quote}
A joint distribution exists, that has the full conditionals (imputation models)
as its conditional distributions.
\end{quote}

\blue{Congeniality:}
\begin{quote}
The imputation model is compatible with the analysis model.
\end{quote}

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Important requirements} for MICE to work well include:
\begin{itemize}
\item Compatibility
\item Congeniality
\item MAR or MCAR (in the standard implementations)
\item \blue{All relevant variables} need to be included. (Omission might result in MNAR.)
\item \textbf{\textcolor{red}{The outcome needs to be included}} as predictor variable\\
      (but we usually do not impute missing outcome values).
\item The imputation models (and analysis model) need to be \blue{correctly specified}
      (which is a requirement in any standard analysis).
\end{itemize}
\end{frame}


\section{Alternatives to MICE}
\subsection{Joint model imputation}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To \blue{avoid incompatible} and \blue{uncongenial} imputation models, we need to
\begin{itemize}
\item specify the joint distribution
\item and derive full conditionals / imputation models from this joint distribution
\end{itemize}
instead of specifying them directly.

\bigskip

\pause
\blue{Problem:}\\
The joint distribution may not be of any known form:

\begin{eqnarray*}
\begin{array}{c}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim N(\mu_2, \sigma_2^2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim N\left(
                \left[
                  \begin{array}{c}
                  \mu_1\\ \mu_2
                  \end{array}
                \right], \left[
                            \begin{array}{cc}
                            \sigma_1^2 & \sigma_{12}\\
                            \sigma_{12} & \sigma_2^2
                            \end{array}
                          \right]
              \right)\\[2ex]
\text{\blue{but}\quad}
\begin{array}{l}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim Bin(\mu_2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim ???
\end{eqnarray*}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Possible approaches:\\\bigskip

Approach 1: \blue{Multivariate Normal Model}\\
Approximate the joint distribution by a known multivariate distribution
\mode<presentation>{
(usually the normal distribution; this is the joint model MI mentioned before).
}
\mode<article>{
(usually the normal distribution; this is the approach mentioned in Part I
in Section~\ref{subsec:multivarmissing}).
}

\bigskip

Approach 2: \blue{Sequential Factorization}\\
Factorize the joint distribution into a (sequence of) conditional and a marginal
distributions.
\end{frame}



\subsection{Sequential Factorization}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\onslide<1->{
The \blue{joint distribution} of two variables $y$ and $x$ can be written
as the product of conditional distributions:
$$p(y,x) = p(y\mid x)\;p(x)$$
(or alternatively $p(y,x) = p(x\mid y)\;p(y)$)
}

\vfill

\onslide<2->{
This can easily be \blue{extended for more variables}:
$$p(y,x_1,\ldots,x_p, X_c) = \underset{\text{analysis model}}{
                             \underbrace{p(y\mid x_1,\ldots,x_p, X_c)}}\;
p(x_1\mid x_2,\ldots,x_p, X_c)\;
\ldots\; p(x_p\mid X_c)$$%

where $x_1, \ldots, x_p$ denote incomplete covariates and $X_c$ contains all
completely observed covariates.
}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The analysis model is part of the specification of the joint distribution.

\blue{\ding{225}} Advantages:
\begin{itemize}
\item<1-> The outcome is \blue{automatically included in the imputation} procedure.
\item<1-> The outcome does not appear in any of the predictors of the imputation
      models:
      \begin{itemize}
      \item \blue{no need to approximate} complex outcomes,
      \item \blue{no need to summarize} complex outcomes.
      \end{itemize}
\item<2-> The parameters of interest are obtained directly\\
      \blue{\ding{225}}
      imputation and analysis in one step
\item<3-> \blue{Non-linear associations} or interactions involving incomplete covariates
      are specified in the analysis model and thereby
      \blue{automatically taken into account}
\end{itemize}


\bigskip

\onslide<4>{Since the joint distribution usually does not have a known form, Gibbs sampling
is used to estimate parameters and sample imputed values.}
\end{frame}


\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\href{https://cran.r-project.org/package=JointAI}{\blue{Joint Analysis and Imputation}}, \\
uses the \blue{sequential factorization approach} to perform
simultaneous analysis and imputation in the Bayesian framework \cite{JointAI, Erler2016, Erler2017}.

\bigskip

\textbf{JointAI} (version 0.6.0) can analyse incomplete data using

\begin{columns}
\begin{column}{0.4\linewidth}
\begin{itemize}
\item linear regression
\item generalized linear regression
\item linear mixed models
\item generalized linear mixed models
\end{itemize}
\end{column}
\begin{column}{0.6\linewidth}
\begin{itemize}
\item (ordinal) cumulative logit regression
\item (ordinal) cumulative logit mixed models
\item parametric (Weibull) survival models
\item Cox proportional hazards models
\end{itemize}
\end{column}
\end{columns}
\vspace*{3ex}
while assuring compatibility between analysis model and imputation models
when non-linear functions or interactions are included.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The necessary \blue{Gibbs sampling} is performed using \blue{\textsf{JAGS}}
(an external program), which is free, but needs to be
installed from \url{https://sourceforge.net/projects/mcmc-jags/files/}.

\bigskip

\blue{JointAI} can be installed from CRAN or \href{https://github.com/nerler/JointAI}{GitHub}:
<<eval = F, size = 'small'>>=
install.packages("devtools")
devtools::install_github("NErler/JointAI")
@


\blue{JointAI} has its own web page (\href{https://nerler.github.io/JointAI/}{https://nerler.github.io/JointAI/})
with several vignettes on \href{https://nerler.github.io/JointAI/articles/VisualizingIncompleteData.html}{Visualization of Incomplete Data},
a \href{https://nerler.github.io/JointAI/articles/MinimalExample.html}{Minimal Example},
details on
\href{https://nerler.github.io/JointAI/articles/ModelSpecification.html}{Model Specification},
\href{https://nerler.github.io/JointAI/articles/}{etc.}
\end{frame}



\section{Imputation with non-linear functional forms}
\subsection{With mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
There is no strategy for MICE that can guarantee valid imputations when
non-linear functional forms and/or interactions are involved,
but some settings in \textbf{mice} may help to reduce bias in the resulting estimates.

\bigskip

For imputation of variables that have non-linear associations
\begin{itemize}
\item PMM often works better than imputation with a normal model,
\item the \blue{J}ust \blue{A}nother \blue{V}ariable approach can reduce bias in interactions,
\item \Rstring{quadratic} can help to impute variables with quadratic association.
% \item inclusion of interaction terms in the imputation model may help.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Just Another Variable (JAV)} approach:
\begin{itemize}
\item pre-calculate the non-linear form (or interaction term) in the incomplete data,
\item add it as a column to the dataset, and
\item impute it as if it was just another variable.
\end{itemize}

\bigskip\pause

\Rstring{quadratic} uses the ``polynomial combination''
method to impute covariates that have a
quadratic association with the outcome \cite[pp. 139--141]{Buuren2012}, \cite{Vink2013}.

\bigskip

This is to ensure the imputed values for $x$ and $x^2$ are consistent,
and to reduce bias in the subsequent analysis that uses $x$ and $x^2$.

\bigskip

In my experience, using \Rstring{quadratic} can lead to numerical problems.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To demonstrate the approaches, we use a simulated example dataset \Robj{DFnonlin}, with
\begin{itemize}
\item continuous outcome $y$
\item continuous (normal) covariate $x$ (50\% missing values MCAR)
\item quadratic effect of $x$ on $y$
\item binary covariate $z$ (complete)
\item interaction between $x$ and $z$
\end{itemize}

\bigskip

\pause
In the naive approach, we leave all settings to the defaults.
<<size = 'small', eval = FALSE>>=
# naive imputation, using only y, x, z
impnaive <- mice(DF_nonlin, printFlag = F)
@

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
We use two different JAV approaches:\\[2ex]
\blue{JAV:} calculating the \blue{quadratic and interaction term} before imputation
<<size = 'small', eval = FALSE>>=
# add quadratic term and interaction to data
DF2 <- DF_nonlin
DF2$xx <- DF2$x^2
DF2$xz <- DF2$x * DF2$z

# JAV imputation
impJAV <- mice(DF2, printFlag = F, maxit = 20)
@

\pause

\blue{JAV2:} additionally using an interaction between $z$ and $y$
<<size = 'small', eval = FALSE>>=
# add interaction between y and z to data
DF3 <- DF2
DF3$yz <- DF3$y * DF3$z

# JAV imputation with additional interaction
impJAV2 <- mice(DF3, printFlag = F, maxit = 20)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
We also try using imputation method \Rstring{quadratic}.
<<warning = F, size = 'small', eval = FALSE>>=
# adapt the imputation method for quadratic imputation
methqdr <- impJAV$meth
methqdr[c("x", "xx", "xz")] <- c("quadratic", "~I(x^2)", "~I(x*z)")

# adapt the predictor matrix
predqdr <- impJAV$pred
predqdr[, "xx"] <- 0

impqdr <- mice(DF2, meth = methqdr, pred = predqdr,
               printFlag = F, maxit = 10)
@
Note: there were warning messages about numerical issues for this approach
(\texttt{glm.fit: fitted probabilities numerically 0 or 1 occurred}).
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\centering\includegraphics[width= \linewidth]{figure/p_comp_nonlin.pdf}
For this example, \blue{none of the approaches provided satisfying results}.
\end{frame}


\subsection{With JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The syntax we use to analyse and impute the current example using \blue{JointAI} is
similar to the specification of a standard linear model using \Rfct{lm}.

<<JointAI_nonlin, eval = FALSE, size = 'small'>>=
library(JointAI)
JointAI_nonlin <- lm_imp(y ~ x*z + I(x^2), data = DF_nonlin,
                         n.iter = 2500)
@


<<getJointAI_nonlin, echo = FALSE, message = FALSE>>=
library(JointAI)
load("workspaces/JointAI_nonlin.RData")
@

\pause

Convergence of the Gibbs sampler can be checked using a traceplot.
<<eval = FALSE>>=
traceplot(JointAI_nonlin, ncol = 3)
@

\pause

Results (no separate analysis \& pooling is necessary) can be obtained with
the \Rfct{summary} function:

<<eval = FALSE>>=
summary(JointAI_nonlin)
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\centering\includegraphics[width = 0.9\linewidth]{figure/traceplotnonlin.pdf}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<size = 'tiny', echo = FALSE>>=
summary(JointAI_nonlin)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\centering\includegraphics[width = \linewidth]{figure/p_comp_nonlin2.pdf}
\end{frame}

\begin{frame}
\begin{beamercolorbox}[sep=8pt,center,wd=\textwidth]{part title}
\usebeamerfont{part title}
Practical
\end{beamercolorbox}

\vfill

To practice imputation with non-linear forms or interaction terms find 
the instructions for the practical here:\\
\begin{block}{}
\centering\url{https://nerler.com/teaching/fgme2019/minonlin}
\end{block}
\end{frame}


\section{Imputation of longitudinal data}
\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\textbf{mice} has functions to allow imputation of longitudinal (2-level) data:
\begin{itemize}
\item \blue{Level 1:}\\
repeated measurements within subjects or subjects within classes
\item \blue{Level 2:}\\
time-constant/baseline covariates, between subjects effects, variables on the group level
\end{itemize}

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.5\textwidth}
Imputation methods for \blue{level-1} variables:
\begin{itemize}
\item \Rstring{2l.pan}
\item \Rstring{2l.norm}
\item \Rstring{2l.lmer}
\item \Rstring{2l.bin}
\end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
Imputation methods for \blue{level-2} variables:
\begin{itemize}
\item \Rstring{2lonly.norm}
\item \Rstring{2lonly.pmm}
\item \Rstring{2lonly.mean}
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2l.pan} uses a linear two-level model with \blue{homogeneous
within group variances} using Gibbs sampling \cite{Schafer2002}.
It needs the package \textbf{pan} to be installed.

\bigskip

\Rstring{2l.pan} allows for different roles of predictor variables, that
can be specified as different values in the \Rarg{predictorMatrix}:
\begin{itemize}
\item grouping/ID variable: -2
\item random effects (also included as fixed effects): 2
\item fixed effects of group means: 3
\item fixed effects of group means \& random effects: 4
\end{itemize}

<<micelong_ex1_cont3_, eval = F, size = 'small'>>=
# random effects of x in model for y
pred["y","x"] <- 2
# fixed effects of x and group mean of x
pred["y","x"] <- 3
# random effects of x and group mean of x
pred["y","x"] <- 4
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2l.norm} implements a (Bayesian) linear two-level model with
\blue{heterogenous} group variances.

In the current implementation all predictors should be specified as random
effects (set to 2 in the \Rarg{predictorMatrix}, because the algorithm does not
handle predictors that are specified as fixed effects).

\bigskip

\pause
\Rstring{2l.lmer}/\Rstring{2l.bin} imputes univariate systematically and sporadically
missing data using a two-level normal/logistic model using \Rfct{lmer}/\Rfct{glmer} from package
\textbf{lme4}.

\bigskip

\pause
\Rstring{2lonly.norm} and \Rstring{2lonly.pmm} can be used
to impute level-2 variables (in combination with \Rstring{2l.pan} for
level-1 variables).

\bigskip

In all cases, the group identifier ("id" variable) needs to be set to -2 in
the \Rarg{predictorMatrix}.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2lonly.mean} imputes values with the mean of the observed values per
class. This method should only be used to fill in values that are known to be
constant per class and have some values observed in each class.

\bigskip

\textbf{Example:}
In a multi-center trial the type of some medical equipment is known to be
the same for all patients treated in the same hospital, but not filled in for
some patients.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
As an example, we will impute the second (unbalanced) longitudinal
data example from above. The data contain
\begin{itemize}
\item $x1$ (complete)
\item $x2$ (binary, 30\% missing values)
\item $x3$ (3 categories, 30\% missing values)
\item $x4$ (continuous/normal, 30\% missing values)
\item $y$ (longitudinal outcome)
\item $time$ (time variable with quadratic effect)
\item $id$ (id variable)
\end{itemize}

\bigskip

Since there is no 2-level method for categorical data, we use \Rstring{2lonly.pmm}
to impute $x2$ and $x3$.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
As usual, we start with the setup run of \Rfct{mice}
<<miceimp_DFexlong2, size = 'small', eval = FALSE>>=
imp0 <- mice(DFexlong2, maxit = 0)
meth <- imp0$method
pred <- imp0$predictorMatrix
@

and adjust the imputation \Rarg{method} and \Rarg{predictorMatrix}
<<miceimp_DFexlong2_02, size = 'small', eval = FALSE>>=
meth[c("x2", "x3")] <- "2lonly.pmm"
meth[c("x4")] <- "2lonly.norm"

pred[, "id"] <- -2  # identify id variable
pred[, "ti"] <- 0 # don't use time-point indicator
@

We can then perform the imputation.
<<miceimp_DFexlong2_03, size = 'small', eval = FALSE>>=
imp <- mice(DFexlong2, maxit = 10, method = meth,
            predictorMatrix = pred, printFlag = FALSE)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The imputed data can be analysed using either \Rfct{lmer} from the package
\textbf{lme4}, or \Rfct{lme} from \textbf{nlme}. Here we use the former.
<<miceimp_DFexlong2_04, size = 'small', eval = FALSE>>=
library(lme4)
models <- with(imp, lmer(y ~ x1 + x2 + x3 + x4 + time + I(time^2) +
                           (time|id),
                         control = lmerControl(optimizer = "Nelder_Mead")
))
mice_longimp <- summary(pool(models), conf.int = TRUE)
@
\end{frame}

\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Linear mixed models with incomplete covariates can also be
analysed using the package \textbf{JointAI}.

\bigskip

The syntax is analogous the syntax used in \Rfct{lme} of the package \textbf{nlme}.

<<JointAI_long, eval = FALSE, size = 'small'>>=
library(JointAI)
JointAI_long <- lme_imp(y ~ x1 + x2 + x3 + x4 + time + I(time^2),
                        random = ~time|id, data = DFexlong2,
                        n.iter = 5000)
@

\pause

Again, convergence of the Gibbs sampler should be checked, e.g., using \Rfct{traceplot}
before obtaining the results.



Contrary to the two-level imputation of \textbf{mice}, non-linear associations
are appropriately handled.
\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\only<beamer>{
\only<1>{
\centering\includegraphics[width = \linewidth]{figure/p_comp_long.pdf}
}}
\only<2>{
\centering\includegraphics[width = \linewidth]{figure/p_comp_long2.pdf}
}
\end{frame}


\begin{frame}
\begin{beamercolorbox}[sep=8pt,center,wd=\textwidth]{part title}
\usebeamerfont{part title}
Practical
\end{beamercolorbox}

\vfill

To practice imputation with longitudinal data find 
the instructions for the practical here:\\
\begin{block}{}
\centering\url{https://nerler.com/teaching/fgme2019/milong}
\end{block}
\end{frame}
